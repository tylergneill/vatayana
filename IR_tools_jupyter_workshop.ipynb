{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:00<00:00, 304.36it/s]\n"
     ]
    }
   ],
   "source": [
    "# create virtual server here in notebook with access to all functions and variables\n",
    "from IR_tools import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search settings\n",
    "\n",
    "# pre-NBhū\n",
    "# non_priority_texts = [\n",
    "#                     \"VS\", \"MīmS\", \"MMK\", \"ViVy\", \"NS\", \"YSBh\", \"SK\", \n",
    "#                     \"ViṃśV\", \"NBh\", \"MīmBh\", \"ĀP\", \"PSV\", \"NPS\", \"TriṃśBh\", \n",
    "#                     \"YD\", \"PDhS\", \"NV\", \"PPad\", \"ŚV\", \"PVSV\", \"PV\", \"PVin\", \n",
    "#                     \"HB\", \"NB\", \"VN\", \"SAS\", \"SP\", \"BhāV\", \"BrS\", \"VibhrV\", \n",
    "#                     \"VidhV\", \"PSṬ\", \"HBṬ\", \"NBṬ\", \"PVA\", \"VSṬ\", \"TUS\"\n",
    "#                  ]\n",
    "\n",
    "# # others\n",
    "# priority_texts = [\n",
    "#                     \"VyV\", \"NM\", \"NyKal\", \"NBhū\", \"SŚP\", \"ŚVK\", \"HBṬĀ\", \n",
    "#                     \"NyKand\", \"AvNir\", \"PVV\", \"TCM\", \"MukV\"\n",
    "#                     ]\n",
    "\n",
    "non_priority_texts = [\n",
    "                    \"VyV\", \"NM\", \"NyKal\", \"NBhū\", \"SŚP\", \"ŚVK\", \"HBṬĀ\", \n",
    "                    \"NyKand\", \"AvNir\", \"PVV\", \"TCM\", \"MukV\",\n",
    "                    \"VS\", \"MīmS\", \"MMK\", \"ViVy\", \"NS\", \"YSBh\", \"SK\", \n",
    "                    \"ViṃśV\", \"NBh\", \"MīmBh\", \"ĀP\", \"PSV\", \"NPS\", \"TriṃśBh\", \n",
    "                    \"YD\", \"PDhS\", \"NV\", \"PPad\", \"ŚV\", \"PVSV\", \"PV\", \"PVin\", \n",
    "                    \"HB\", \"NB\", \"VN\", \"SAS\", \"SP\", \"BhāV\", \"BrS\", \"VibhrV\", \n",
    "                    \"VidhV\", \"PSṬ\", \"HBṬ\", \"NBṬ\", \"PVA\", \"VSṬ\", \"TUS\"\n",
    "                 ]\n",
    "\n",
    "# others\n",
    "priority_texts = [\n",
    "                    \"PVA\"\n",
    "                    ]\n",
    "\n",
    "N_tf_idf_shallow = int( len(doc_ids) * 0.15)\n",
    "N_sw_w_shallow = 200\n",
    "\n",
    "N_tf_idf_deep = int( len(doc_ids) * 1.00)\n",
    "N_sw_w_deep = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions for assessing speed and summarizing results \n",
    "\n",
    "from datetime import datetime, date\n",
    "from time import sleep\n",
    "\n",
    "def calc_dur(start, end):\n",
    "    delta = datetime.combine(date.today(), end) - datetime.combine(date.today(), start)\n",
    "    duration_secs = delta.seconds + delta.microseconds / 1000000\n",
    "    return duration_secs\n",
    "\n",
    "def summarize_result(results, label, duration, num_comparisons, display_depth):\n",
    "    print('{} ({:.3f} s, {} comparisons, {:.6f} s/comparison)'.format(\n",
    "            label,\n",
    "            duration, \n",
    "            num_comparisons,\n",
    "            duration/num_comparisons\n",
    "            )\n",
    "    )\n",
    "    for k,v in list(results.items())[:display_depth]:\n",
    "        print(k, \": \", v)\n",
    "    print()\n",
    "    sleep(0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# streamlined version of get_closest_docs() with no HTML rendering, for assessing speed of algorithm parts\n",
    "\n",
    "def get_closest_docs_2(query_id, search_depth='shallow', prioritze=True, display_depth=10, mode='speed_summary'):\n",
    "    \n",
    "    if search_depth=='shallow':\n",
    "        N_tf_idf = N_tf_idf_shallow\n",
    "        N_sw_w = N_sw_w_shallow\n",
    "    elif search_depth=='deep':\n",
    "        N_tf_idf = N_tf_idf_deep\n",
    "        N_sw_w = N_sw_w_deep\n",
    "    \n",
    "    # rank candidates by topic similarity\n",
    "\n",
    "    start1 = datetime.now().time()\n",
    "    all_topic_candidates = rank_all_candidates_by_topic_similarity(\n",
    "        query_id\n",
    "        )    \n",
    "    end1 = datetime.now().time()\n",
    "    topic_time = calc_dur(start1, end1)\n",
    "    if mode=='speed_summary': summarize_result(\n",
    "        results=all_topic_candidates,\n",
    "        label='topics',\n",
    "        duration=topic_time,\n",
    "        num_comparisons=len(doc_ids),\n",
    "        display_depth=display_depth\n",
    "    )\n",
    "\n",
    "    if prioritze:\n",
    "        # prioritize candidates by text name, discard secondary candidates\n",
    "            priority_candidate_ids, _ = divide_doc_id_list_by_work_priority(\n",
    "                list(all_topic_candidates.keys()),\n",
    "                priority_texts\n",
    "                )\n",
    "            priority_topic_candidates = { doc_id: all_topic_candidates[doc_id]\n",
    "                for doc_id in priority_candidate_ids\n",
    "                }\n",
    "    else:\n",
    "        # don't prioritize\n",
    "        priority_topic_candidates = all_topic_candidates\n",
    "        priority_topic_candidate_ids = list(all_topic_candidates.keys())\n",
    "    \n",
    "    # limit further computation to only top N_tf_idf of sorted candidates (minus query itself)\n",
    "    pruned_priority_topic_candidates = { k:v\n",
    "        for (k,v) in list(priority_topic_candidates.items())[:N_tf_idf-1]\n",
    "        }\n",
    "\n",
    "    # further rank candidates by tiny tf-idf\n",
    "    start2 = datetime.now().time()\n",
    "    tf_idf_candidates = rank_candidates_by_tiny_TF_IDF_similarity(\n",
    "        query_id,\n",
    "        list(pruned_priority_topic_candidates.keys())\n",
    "        )\n",
    "    end2 = datetime.now().time()\n",
    "    tf_idf_time = calc_dur(start2, end2)\n",
    "    if mode=='speed_summary': summarize_result(\n",
    "        results=tf_idf_candidates,\n",
    "        label='tf-idf',\n",
    "        duration=tf_idf_time,\n",
    "        num_comparisons=N_tf_idf,\n",
    "        display_depth=display_depth\n",
    "    )\n",
    "\n",
    "    # limit further computation to only top N_sw_w of sorted candidates\n",
    "    pruned_tf_idf_candidates = { k:v\n",
    "        for (k,v) in list(tf_idf_candidates.items())[:N_sw_w-1]\n",
    "        }\n",
    "\n",
    "    # further rank candidates by sw_w\n",
    "    start3 = datetime.now().time()\n",
    "    sw_w_candidates = rank_candidates_by_sw_w_alignment_score(\n",
    "        query_id,\n",
    "        list(pruned_tf_idf_candidates.keys())\n",
    "        )\n",
    "    end3 = datetime.now().time()\n",
    "    sw_w_time = calc_dur(start3, end3)\n",
    "\n",
    "    # do not convert sw_w scores of 0.0 to empty string\n",
    "    # do not add blank entries for other docs for which sw_w comparison not performed\n",
    "\n",
    "    if mode=='speed_summary':\n",
    "        summarize_result(\n",
    "            results=sw_w_candidates, \n",
    "            label='sw_w', \n",
    "            duration=sw_w_time, \n",
    "            num_comparisons=N_sw_w, \n",
    "            display_depth=display_depth\n",
    "        )\n",
    "        return\n",
    "\n",
    "    elif mode=='evaluate_pairs':\n",
    "        return all_topic_candidates, priority_topic_candidates, tf_idf_candidates, sw_w_candidates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topics (0.254 s, 28381 comparisons, 0.000009 s/comparison)\n",
      "PVA_629,vi :  0.9698818351650111\n",
      "PVSV_010,13_010,15 :  0.9523222396152328\n",
      "NBṬ_217,iii_217,v :  0.9382695193578188\n",
      "PVSV_010,19_010,21 :  0.9165924117385076\n",
      "PVin_II,045,iii :  0.913539875583041\n",
      "PVA_612,i_612,iii :  0.9116307949243329\n",
      "PVV_290,iv_290,v :  0.895139987240839\n",
      "PVV_493,viii_493,x :  0.8912334689992081\n",
      "PVin_I,091,i_I,092,i :  0.8910857329884588\n",
      "PVin_II,123,i_II,123,ii :  0.8907492314066945\n",
      "\n",
      "tf-idf (1.186 s, 4257 comparisons, 0.000278 s/comparison)\n",
      "PVA_607,iv_607,vii :  0.12628304328524773\n",
      "PVA_105,v_105,viii :  0.09473520254494294\n",
      "PVA_177,ix_177,x :  0.07675169020226831\n",
      "PVA_579,xiii_580,iii :  0.07390409955511276\n",
      "PVA_646,vii :  0.07089164557978594\n",
      "PVA_647,xii_647,xiii :  0.06991441639858155\n",
      "PVA_359,viii_359,xii :  0.06936173625011136\n",
      "PVA_133,i_133,iv :  0.06928604427807285\n",
      "PVA_485,vii_485,viii :  0.06912142848728745\n",
      "PVA_372,vi^1 :  0.0658604994672576\n",
      "\n",
      "sw_w (0.965 s, 200 comparisons, 0.004825 s/comparison)\n",
      "PVA_105,v_105,viii :  24.4\n",
      "PVA_555,vi_555,vii :  17.0\n",
      "PVA_628,ii_628,vi :  16.0\n",
      "PVA_646,viii_646,x :  16.0\n",
      "PVA_067,ix_067,xi :  15.0\n",
      "PVA_611,xii_611,xiv :  15.0\n",
      "PVA_325,x_325,xi :  15.0\n",
      "PVA_335,i :  14.0\n",
      "PVA_647,xiv_647,xix :  14.0\n",
      "PVA_135,vi_135,viii :  13.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test single 'speed_summary' run, shallow (no values returned)\n",
    "\n",
    "get_closest_docs_2('NBhū_142,19', search_depth='shallow', display_depth=10, mode='speed_summary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run for 'speed_summary', deep (no values returned)\n",
    "\n",
    "# get_closest_docs_2('NBhū_142,19', search_depth='deep', display_depth=10, mode='speed_summary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1765 NBhū_104,6^1 NBhū_154,15 140\n",
      "140\n"
     ]
    }
   ],
   "source": [
    "# identify my NBhū docs\n",
    "\n",
    "NBhu_doc_ids = [ di for di in doc_ids if parse_complex_doc_id(di)[0] == 'NBhū' ]\n",
    "print(len(NBhu_doc_ids), NBhu_doc_ids[238], NBhu_doc_ids[377], 377-238+1)\n",
    "\n",
    "doc_id_full_list = NBhu_doc_ids[238:377+1]\n",
    "print(len(doc_id_full_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# doc_ids.index(\"PVV_154,i_154,iii\")\n",
    "# doc_ids.index(\"PVV_176,vi_176,vii\")\n",
    "doc_id_full_list = doc_ids[14265:14340]\n",
    "# 14265 = \"PVV_154,i_154,iii\"\n",
    "# 14340 = \"PVV_176,vi_176,vii\"\n",
    "len(doc_id_full_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or do this for ALL NBhū docs (!)\n",
    "\n",
    "# doc_id_full_list = NBhu_doc_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up doc pairs to evaluate as expected from benchmark\n",
    "\n",
    "doc_id_suspected_pair_list = [\n",
    "    ('NBhū_104,6^1', 'PVin_I,034,i'),\n",
    "    ('NBhū_104,6^2', 'PV_3.148ab_3.150cd'),\n",
    "    ('NBhū_104,6^2', 'NS_4.2.8_4.2.14'),\n",
    "    ('NBhū_106,3', 'NS_4.2.23_4.2.28'),\n",
    "    ('NBhū_106,3', 'NV_487,02_487,04'),\n",
    "    ('NBhū_106,11_107,1', 'ViṃśV_93,i_95,i'),\n",
    "    ('NBhū_106,11_107,1', 'PVin_I,035,i_I,036,ii'),\n",
    "    ('NBhū_106,11_107,1', 'NS_4.2.15_4.2.22'),\n",
    "    ('NBhū_107,6_108,1', 'PVin_I,039,i_I,039,ii'),\n",
    "    ('NBhū_108,4_108,6', 'PVin_I,040,i'),\n",
    "    ('NBhū_108,10', 'PVin_I,041,i'),\n",
    "    ('NBhū_108,10', 'PV_3.431cd_3.434cd'),\n",
    "    ('NBhū_109,1', 'PV_3.431cd_3.434cd'),\n",
    "    ('NBhū_109,7', 'PV_3.329ab_3.332ab'),\n",
    "    ('NBhū_109,7', 'PVin_I,035,i_I,036,ii'),\n",
    "    ('NBhū_115,1_115,4', 'PV_3.281ab_3.284ab'),\n",
    "    ('NBhū_115,18', 'PVA_289,xiv_290,ii'),\n",
    "    ('NBhū_115,18', 'PVA_290,iii'),\n",
    "    ('NBhū_115,18', 'PVA_290,iv_290,vi'),\n",
    "    ('NBhū_116,7', 'NS_4.1.35_4.1.42'),\n",
    "    ('NBhū_116,7', 'NV_454,17_454,18'),\n",
    "    ('NBhū_117,3^1', 'PVA_288,vii'),\n",
    "    ('NBhū_117,3^2', 'PVA_288,vii'),\n",
    "    ('NBhū_117,3^2', 'PV_3.208cd_3.211ab'),\n",
    "    ('NBhū_121,2^2', 'PVin_I,046,i_I,046,iii'),\n",
    "    ('NBhū_124,8^2', 'PV_2.066ab_2.069ab'),\n",
    "    ('NBhū_125,15', 'ŚV_5,4.250ab_5,4.253ab'),\n",
    "    ('NBhū_126,6^1', 'NS_4.2.8_4.2.14'),\n",
    "    ('NBhū_126,6^1', 'NBh_1047,i_1047,ii'),\n",
    "    ('NBhū_126,6^1', 'NS_2.1.33_2.1.39'),\n",
    "    ('NBhū_126,6^3', 'NS_2.1.33_2.1.39'),\n",
    "    ('NBhū_126,6^3', 'NS_4.2.8_4.2.14'),\n",
    "    ('NBhū_131,11_131,17', 'ViṃśV_93,i_95,i'),\n",
    "    ('NBhū_132,2', 'NS_4.2.15_4.2.22'),\n",
    "    ('NBhū_132,11^1', 'TUS_ii,102,i_ii,102,ii'),\n",
    "    ('NBhū_132,11^1', 'PV_3.386cd_3.389cd'),\n",
    "    ('NBhū_138,9', 'PVA_353,x'),\n",
    "    ('NBhū_138,9', 'PVA_353,xi_353,xii'),\n",
    "    ('NBhū_139,1_139,3', 'PVA_353,xiii_353,xv'),\n",
    "    ('NBhū_139,1_139,3', 'PVSV_022,06_022,20'),\n",
    "    ('NBhū_139,1_139,3', 'PVin_I,086,ii^1'),\n",
    "    ('NBhū_139,26_140,1', 'PV_3.326ab_3.328cd'),\n",
    "    ('NBhū_140,21', 'PVin_I,046,i_I,046,iii'),\n",
    "    ('NBhū_142,2', 'PV_3.329ab_3.332ab'),\n",
    "    ('NBhū_142,12', 'PVA_387,xvii_387,xxii'),\n",
    "    ('NBhū_142,12', 'PVA_359,iv_359,vi'),\n",
    "    ('NBhū_142,19', 'PVA_361,xiii_361,xvi'),\n",
    "    ('NBhū_142,19', 'PVSV_010,13_010,15'),\n",
    "    ('NBhū_142,19', 'PVSV_010,19_010,21'),\n",
    "    ('NBhū_142,19', 'PVin_I,091,i_I,092,i'),\n",
    "    ('NBhū_142,19', 'PVin_I,092,ii_I,092,iii'),\n",
    "    ('NBhū_144,20^1', 'PVA_361,xiii_361,xvi'),\n",
    "    ('NBhū_145,15', 'PVA_360,ix'),\n",
    "    ('NBhū_145,15', 'PVA_360,x'),\n",
    "    ('NBhū_145,22', 'PVA_360,x'),\n",
    "    ('NBhū_145,22', 'PVA_360,xi_361,i'),\n",
    "    ('NBhū_146,7', 'PVA_360,xi_361,i'),\n",
    "    ('NBhū_146,7', 'PVA_361,ii_361,iii'),\n",
    "    ('NBhū_146,14_146,18', 'PVA_361,ii_361,iii'),\n",
    "    ('NBhū_146,14_146,18', 'PVA_361,iv_361,vi'),\n",
    "    ('NBhū_146,21', 'PVA_361,iv_361,vi'),\n",
    "    ('NBhū_146,21', 'PVA_361,vii'),\n",
    "    ('NBhū_147,3_147,6', 'PVA_361,x_361,xii'),\n",
    "    ('NBhū_149,4_149,16', 'PVA_366,v_366,ix'),\n",
    "    ('NBhū_149,19', 'PVA_366,iv'),\n",
    "    ('NBhū_150,1', 'HB_3,1^1'),\n",
    "    ('NBhū_150,1', 'PV_2.001ab_2.005cd'),\n",
    "    ('NBhū_150,6^2', 'PVin_II,001,i_II,001,ii'),\n",
    "    ('NBhū_150,6^2', 'NB_3.1_3.8'),\n",
    "    ('NBhū_153,4_153,7', 'PVA_356,iv_356,vii'),\n",
    "    ('NBhū_153,14', 'PVA_358,ix^4')\n",
    "]\n",
    "doc_id_suspected_pair_list = []\n",
    "\n",
    "num_expected_pairs = len(doc_id_suspected_pair_list)\n",
    "\n",
    "# turn into dict of lists\n",
    "doc_id_suspected_pair_dict = {}\n",
    "for doc_id_1, doc_id_2 in doc_id_suspected_pair_list:\n",
    "    if doc_id_1 not in doc_id_suspected_pair_dict:\n",
    "        doc_id_suspected_pair_dict[doc_id_1] = [doc_id_2]\n",
    "    else:\n",
    "        doc_id_suspected_pair_dict[doc_id_1].append(doc_id_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for describing doc_id's position in ranked results as well as giving absolute score\n",
    "\n",
    "def format_score_summary(ranking_dict, doc_id):\n",
    "\n",
    "    if doc_id in ranking_dict:\n",
    "\n",
    "        ks = list(ranking_dict.keys())\n",
    "        rank = ks.index(doc_id) + 1\n",
    "        score = ranking_dict[doc_id]\n",
    "\n",
    "        return \"{} ({:.2f})\".format(rank, score)\n",
    "\n",
    "    else:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b781cf9f6b645c092c05e043c53713b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=75.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PVV_154,i_154,iii\n",
      "NOVEL PAIR (PVV_154,i_154,iii, PVA_245,vi_245,vii): 356 (0.63) 52 (0.63) 1 (0.45) 1 (97.40)\n",
      "novel pairs (@50): 1\n",
      "\n",
      "PVV_154,iv_154,vi\n",
      "NOVEL PAIR (PVV_154,iv_154,vi, PVA_245,viii_245,ix): 178 (0.66) 23 (0.66) 1 (0.50) 1 (86.80)\n",
      "novel pairs (@50): 1\n",
      "\n",
      "PVV_155,i_155,iii\n",
      "NOVEL PAIR (PVV_155,i_155,iii, PVA_246,i_246,ii): 775 (0.40) 162 (0.40) 1 (0.32) 1 (81.00)\n",
      "novel pairs (@50): 1\n",
      "\n",
      "PVV_155,iv_155,vi\n",
      "NOVEL PAIR (PVV_155,iv_155,vi, PVA_246,viii_246,ix): 894 (0.34) 133 (0.34) 1 (0.19) 1 (84.00)\n",
      "novel pairs (@50): 1\n",
      "\n",
      "PVV_155,vii_155,ix\n",
      "NOVEL PAIR (PVV_155,vii_155,ix, PVA_247,iv_247,vi): 398 (0.52) 56 (0.52) 1 (0.30) 1 (89.40)\n",
      "novel pairs (@50): 1\n",
      "\n",
      "PVV_155,x_155,xi\n",
      "(none)\n",
      "\n",
      "PVV_155,xii_155,xiii\n",
      "NOVEL PAIR (PVV_155,xii_155,xiii, PVA_247,vii_247,ix): 403 (0.48) 23 (0.48) 1 (0.39) 1 (96.00)\n",
      "novel pairs (@50): 1\n",
      "\n",
      "PVV_156,i_156,ii\n",
      "NOVEL PAIR (PVV_156,i_156,ii, PVA_247,xi_247,xii): 20 (0.79) 1 (0.79) 1 (0.54) 1 (91.00)\n",
      "novel pairs (@50): 1\n",
      "\n",
      "PVV_156,iii_156,v\n",
      "NOVEL PAIR (PVV_156,iii_156,v, PVA_248,i_248,iii): 1471 (0.26) 233 (0.26) 1 (0.15) 1 (89.40)\n",
      "novel pairs (@50): 1\n",
      "\n",
      "PVV_156,vi_156,x\n",
      "(none)\n",
      "\n",
      "PVV_156,xi_156,xii\n",
      "NOVEL PAIR (PVV_156,xi_156,xii, PVA_249,i_249,iii): 752 (0.41) 135 (0.41) 1 (0.27) 1 (92.20)\n",
      "novel pairs (@50): 1\n",
      "\n",
      "PVV_157,i\n",
      "(none)\n",
      "\n",
      "PVV_157,ii_157,iv\n",
      "NOVEL PAIR (PVV_157,ii_157,iv, PVA_249,v_249,vi): 1624 (0.25) 267 (0.25) 2 (0.20) 1 (89.60)\n",
      "novel pairs (@50): 1\n",
      "\n",
      "PVV_157,v_157,vii\n",
      "NOVEL PAIR (PVV_157,v_157,vii, PVA_249,vii_250,ii): 186 (0.55) 32 (0.55) 1 (0.20) 1 (82.80)\n",
      "novel pairs (@50): 1\n",
      "\n",
      "PVV_157,viii_158,i\n",
      "NOVEL PAIR (PVV_157,viii_158,i, PVA_250,iv_250,vi): 8 (0.87) 1 (0.87) 1 (0.29) 1 (91.00)\n",
      "novel pairs (@50): 1\n",
      "\n",
      "PVV_158,ii_158,iii\n",
      "NOVEL PAIR (PVV_158,ii_158,iii, PVA_250,iv_250,vi): 54 (0.82) 9 (0.82) 1 (0.34) 1 (97.40)\n",
      "novel pairs (@50): 1\n",
      "\n",
      "PVV_158,iv_158,vi\n",
      "NOVEL PAIR (PVV_158,iv_158,vi, PVA_250,viii_251,iii): 39 (0.87) 9 (0.87) 1 (0.38) 1 (94.00)\n",
      "novel pairs (@50): 1\n",
      "\n",
      "PVV_158,vii_158,x\n",
      "(none)\n",
      "\n",
      "PVV_159,i\n",
      "(none)\n",
      "\n",
      "PVV_159,ii_159,iv\n",
      "NOVEL PAIR (PVV_159,ii_159,iv, PVA_251,iv_251,vi): 111 (0.67) 20 (0.67) 3 (0.10) 1 (79.80)\n",
      "novel pairs (@50): 1\n",
      "\n",
      "PVV_159,v_159,vi\n",
      "NOVEL PAIR (PVV_159,v_159,vi, PVA_251,viii_251,x): 26 (0.83) 4 (0.83) 1 (0.41) 1 (88.40)\n",
      "novel pairs (@50): 1\n",
      "\n",
      "PVV_159,vii_159,viii\n",
      "NOVEL PAIR (PVV_159,vii_159,viii, PVA_251,xi_252,i): 223 (0.69) 30 (0.69) 1 (0.41) 1 (130.00)\n",
      "novel pairs (@50): 1\n",
      "\n",
      "PVV_159,ix_160,i\n",
      "NOVEL PAIR (PVV_159,ix_160,i, PVA_251,xi_252,i): 190 (0.68) 24 (0.68) 1 (0.21) 1 (90.60)\n",
      "novel pairs (@50): 1\n",
      "\n",
      "PVV_160,ii_160,iv\n",
      "NOVEL PAIR (PVV_160,ii_160,iv, PVA_252,iii_252,v): 67 (0.85) 9 (0.85) 1 (0.12) 1 (93.20)\n",
      "novel pairs (@50): 1\n",
      "\n",
      "PVV_160,v_160,vii\n",
      "NOVEL PAIR (PVV_160,v_160,vii, PVA_253,iv_253,vii): 36 (0.88) 3 (0.88) 1 (0.30) 1 (92.60)\n",
      "novel pairs (@50): 1\n",
      "\n",
      "PVV_161,i_161,ii\n",
      "NOVEL PAIR (PVV_161,i_161,ii, PVA_253,iv_253,vii): 44 (0.81) 5 (0.81) 1 (0.43) 1 (93.40)\n",
      "novel pairs (@50): 1\n",
      "\n",
      "PVV_161,iii_161,viii\n",
      "NOVEL PAIR (PVV_161,iii_161,viii, PVA_254,ix_254,xi): 1819 (0.26) 355 (0.26) 3 (0.21) 1 (55.60)\n",
      "novel pairs (@50): 1\n",
      "\n",
      "PVV_161,ix_161,xi\n",
      "NOVEL PAIR (PVV_161,ix_161,xi, PVA_254,ix_254,xi): 304 (0.66) 59 (0.66) 2 (0.24) 1 (94.80)\n",
      "novel pairs (@50): 1\n",
      "\n",
      "PVV_162,i_162,vi\n",
      "NOVEL PAIR (PVV_162,i_162,vi, PVA_255,v_255,x): 3 (0.79) 1 (0.79) 1 (0.39) 1 (58.00)\n",
      "novel pairs (@50): 1\n",
      "\n",
      "PVV_162,vii_162,xii\n",
      "(none)\n",
      "\n",
      "PVV_162,xiii_162,xv\n",
      "NOVEL PAIR (PVV_162,xiii_162,xv, PVA_255,xi_256,i): 179 (0.60) 14 (0.60) 2 (0.28) 1 (119.80)\n",
      "novel pairs (@50): 1\n",
      "\n",
      "PVV_163,i_163,iii\n",
      "NOVEL PAIR (PVV_163,i_163,iii, PVA_256,iii_256,v): 63 (0.80) 2 (0.80) 1 (0.51) 1 (85.00)\n",
      "novel pairs (@50): 1\n",
      "\n",
      "PVV_163,iv_163,ix\n",
      "NOVEL PAIR (PVV_163,iv_163,ix, PVA_256,ix): 61 (0.58) 3 (0.58) 2 (0.25) 1 (85.80)\n",
      "NOVEL PAIR (PVV_163,iv_163,ix, PVA_256,vi_256,viii): 1036 (0.37) 103 (0.37) 1 (0.30) 2 (64.80)\n",
      "novel pairs (@50): 2\n",
      "\n",
      "PVV_163,x_164,iv\n",
      "(none)\n",
      "\n",
      "PVV_164,v\n",
      "(none)\n",
      "\n",
      "PVV_164,vi_164,viii\n",
      "(none)\n",
      "\n",
      "PVV_165,i_165,ii\n",
      "(none)\n",
      "\n",
      "PVV_165,iii_165,vi\n",
      "NOVEL PAIR (PVV_165,iii_165,vi, PVA_258,xi_258,xv): 67 (0.75) 5 (0.75) 1 (0.45) 1 (86.40)\n",
      "novel pairs (@50): 1\n",
      "\n",
      "PVV_165,vii_165,ix\n",
      "NOVEL PAIR (PVV_165,vii_165,ix, PVA_259,ii_259,iii): 71 (0.74) 7 (0.74) 1 (0.48) 1 (88.60)\n",
      "novel pairs (@50): 1\n",
      "\n",
      "PVV_166,i_166,v\n",
      "(none)\n",
      "\n",
      "PVV_166,vi_166,viii\n",
      "NOVEL PAIR (PVV_166,vi_166,viii, PVA_260,i_260,ii^1): 3 (0.92) 1 (0.92) 1 (0.26) 1 (79.20)\n",
      "novel pairs (@50): 1\n",
      "\n",
      "PVV_166,ix_167,i\n",
      "NOVEL PAIR (PVV_166,ix_167,i, PVA_260,vii_260,ix): 669 (0.47) 103 (0.47) 1 (0.14) 1 (91.20)\n",
      "novel pairs (@50): 1\n",
      "\n",
      "PVV_167,ii_167,iv\n",
      "NOVEL PAIR (PVV_167,ii_167,iv, PVA_260,vii_260,ix): 1092 (0.38) 151 (0.38) 1 (0.32) 1 (92.40)\n",
      "novel pairs (@50): 1\n",
      "\n",
      "PVV_167,v_167,ix\n",
      "(none)\n",
      "\n",
      "PVV_167,x_167,xi\n",
      "NOVEL PAIR (PVV_167,x_167,xi, PVA_262,i_262,iii): 3 (1.00) 1 (1.00) 1 (0.56) 1 (87.40)\n",
      "novel pairs (@50): 1\n",
      "\n",
      "PVV_168,i_168,iii\n",
      "NOVEL PAIR (PVV_168,i_168,iii, PVA_262,v_262,vi): 8 (0.84) 2 (0.84) 1 (0.35) 1 (92.40)\n",
      "novel pairs (@50): 1\n",
      "\n",
      "PVV_168,iv_168,vi\n",
      "NOVEL PAIR (PVV_168,iv_168,vi, PVA_262,vii_262,ix): 7 (0.99) 2 (0.99) 1 (0.27) 1 (93.40)\n",
      "novel pairs (@50): 1\n",
      "\n",
      "PVV_168,vii_168,ix\n",
      "NOVEL PAIR (PVV_168,vii_168,ix, PVA_262,x_263,ii): 8 (0.91) 2 (0.91) 1 (0.35) 1 (98.20)\n",
      "novel pairs (@50): 1\n",
      "\n",
      "PVV_169,i_169,iii\n",
      "NOVEL PAIR (PVV_169,i_169,iii, PVA_262,x_263,ii): 44 (0.96) 7 (0.96) 2 (0.31) 1 (94.40)\n",
      "novel pairs (@50): 1\n",
      "\n",
      "PVV_169,iv_169,vi\n",
      "NOVEL PAIR (PVV_169,iv_169,vi, PVA_263,iv_263,vi): 20 (0.98) 3 (0.98) 1 (0.32) 1 (107.80)\n",
      "novel pairs (@50): 1\n",
      "\n",
      "PVV_169,vii_169,viii\n",
      "NOVEL PAIR (PVV_169,vii_169,viii, PVA_263,vii_263,viii): 1 (0.98) 1 (0.98) 1 (0.34) 1 (50.20)\n",
      "novel pairs (@50): 1\n",
      "\n",
      "PVV_169,ix_170,i\n",
      "(none)\n",
      "\n",
      "PVV_170,ii_170,vi\n",
      "NOVEL PAIR (PVV_170,ii_170,vi, PVA_264,i_264,iii): 115 (0.87) 14 (0.87) 1 (0.47) 1 (71.60)\n",
      "novel pairs (@50): 1\n",
      "\n",
      "PVV_170,vii_170,ix\n",
      "NOVEL PAIR (PVV_170,vii_170,ix, PVA_264,xiii_264,xv): 186 (0.56) 25 (0.56) 1 (0.27) 1 (86.00)\n",
      "novel pairs (@50): 1\n",
      "\n",
      "PVV_170,x_170,xii\n",
      "NOVEL PAIR (PVV_170,x_170,xii, PVA_266,i_266,ii): 345 (0.67) 58 (0.67) 1 (0.24) 1 (82.00)\n",
      "novel pairs (@50): 1\n",
      "\n",
      "PVV_171,i_171,iii\n",
      "NOVEL PAIR (PVV_171,i_171,iii, PVA_266,vi_266,viii): 60 (0.64) 5 (0.64) 1 (0.20) 1 (79.60)\n",
      "novel pairs (@50): 1\n",
      "\n",
      "PVV_171,iv_171,vi\n",
      "NOVEL PAIR (PVV_171,iv_171,vi, PVA_267,iv_267,v): 968 (0.43) 165 (0.43) 1 (0.31) 1 (89.60)\n",
      "novel pairs (@50): 1\n",
      "\n",
      "PVV_171,vii_171,ix\n",
      "NOVEL PAIR (PVV_171,vii_171,ix, PVA_269,viii_269,ix): 31 (0.83) 4 (0.83) 1 (0.40) 1 (92.80)\n",
      "novel pairs (@50): 1\n",
      "\n",
      "PVV_171,x_172,i\n",
      "NOVEL PAIR (PVV_171,x_172,i, PVA_270,iii_270,iv): 923 (0.48) 229 (0.48) 1 (0.45) 1 (103.80)\n",
      "novel pairs (@50): 1\n",
      "\n",
      "PVV_172,ii_172,iii\n",
      "(none)\n",
      "\n",
      "PVV_172,iv_172,vi\n",
      "NOVEL PAIR (PVV_172,iv_172,vi, PVA_271,i_271,iv): 685 (0.49) 153 (0.49) 1 (0.47) 1 (102.20)\n",
      "novel pairs (@50): 1\n",
      "\n",
      "PVV_172,vii_172,ix\n",
      "NOVEL PAIR (PVV_172,vii_172,ix, PVA_271,x_272,i): 628 (0.51) 378 (0.51) 1 (0.23) 1 (81.60)\n",
      "novel pairs (@50): 1\n",
      "\n",
      "PVV_173,i_173,iv\n",
      "NOVEL PAIR (PVV_173,i_173,iv, PVA_272,iv_272,v): 1977 (0.18) 465 (0.18) 1 (0.31) 1 (69.00)\n",
      "novel pairs (@50): 1\n",
      "\n",
      "PVV_173,v\n",
      "NOVEL PAIR (PVV_173,v, PVA_274,v_274,vii): 820 (0.43) 136 (0.43) 1 (0.36) 1 (138.80)\n",
      "NOVEL PAIR (PVV_173,v, PVA_273,i_273,iii): 62 (0.70) 13 (0.70) 2 (0.32) 2 (78.00)\n",
      "NOVEL PAIR (PVV_173,v, PVA_272,vii_272,ix): 2925 (0.17) 536 (0.17) 34 (0.07) 3 (61.20)\n",
      "novel pairs (@50): 3\n",
      "\n",
      "PVV_173,vi^1\n",
      "(none)\n",
      "\n",
      "PVV_173,vi^2\n",
      "(none)\n",
      "\n",
      "PVV_174,i_174,iii\n",
      "NOVEL PAIR (PVV_174,i_174,iii, PVA_274,viii_274,xi): 363 (0.60) 60 (0.60) 1 (0.38) 1 (92.40)\n",
      "novel pairs (@50): 1\n",
      "\n",
      "PVV_174,iv_174,vi\n",
      "NOVEL PAIR (PVV_174,iv_174,vi, PVA_274,xiii_275,i): 23 (0.70) 5 (0.70) 1 (0.28) 1 (86.20)\n",
      "novel pairs (@50): 1\n",
      "\n",
      "PVV_174,vii_174,ix\n",
      "NOVEL PAIR (PVV_174,vii_174,ix, PVA_275,xiii_275,xvi): 184 (0.58) 23 (0.58) 2 (0.23) 1 (102.60)\n",
      "novel pairs (@50): 1\n",
      "\n",
      "PVV_175,i_175,iii\n",
      "NOVEL PAIR (PVV_175,i_175,iii, PVA_276,ix_276,xi): 801 (0.48) 69 (0.48) 1 (0.28) 1 (51.00)\n",
      "novel pairs (@50): 1\n",
      "\n",
      "PVV_175,iv_175,vi\n",
      "NOVEL PAIR (PVV_175,iv_175,vi, PVA_276,ix_276,xi): 7 (0.77) 2 (0.77) 1 (0.58) 1 (96.20)\n",
      "novel pairs (@50): 1\n",
      "\n",
      "PVV_175,vii_175,ix\n",
      "(none)\n",
      "\n",
      "PVV_175,x_175,xii\n",
      "(none)\n",
      "\n",
      "PVV_176,i_176,ii\n",
      "(none)\n",
      "\n",
      "PVV_176,iii_176,v\n",
      "NOVEL PAIR (PVV_176,iii_176,v, PVA_278,ii_278,vii): 5 (0.78) 1 (0.78) 1 (0.41) 1 (94.20)\n",
      "novel pairs (@50): 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# compare performance against benchmark\n",
    "# i.e., loop over get_closest_docs_2() in mode='evaluate_pairs'\n",
    "# outputs to tsv spreadsheet\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "pbar = tqdm(total=len(doc_id_full_list))\n",
    "\n",
    "output_buffer_1 = \"\"\n",
    "output_buffer_2 = '\\t'.join([\n",
    "    \"doc_id\", \"num_expected_pairs\", \"num_pairs_confirmed\",\n",
    "    \"num_novel_pairs[50]\", \"num_novel_pairs[40]\", \"num_novel_pairs[30]\"\n",
    "    ]) + '\\n'\n",
    "i = 0\n",
    "rank_threshold = 5 # this determines whether system \"CONFIRMS\" an expected pair\n",
    "sw_w_min_threshold = 50 # this determines a \"NOVEL PAIR\"\n",
    "sw_w_threshold_for_display = 50\n",
    "for doc_id_1 in doc_id_full_list:\n",
    "\n",
    "    # announce new doc_id_1\n",
    "    \n",
    "    print()\n",
    "    print(doc_id_1)\n",
    "    something_to_say = False # in case totally uneventful, will output \"(none)\"\n",
    "\n",
    "    # perform full search of doc_id_1 with get_closest_docs_2() in 'evaluate_pairs' mode\n",
    "\n",
    "    all_topic_candidates, priority_topic_candidates, tf_idf_candidates, sw_w_candidates = get_closest_docs_2(\n",
    "        doc_id_1, search_depth='shallow', mode='evaluate_pairs'\n",
    "    )\n",
    "\n",
    "    # get doc_id_2 pair suspects\n",
    "\n",
    "    if doc_id_1 in doc_id_suspected_pair_dict:\n",
    "        doc_id_2_list = doc_id_suspected_pair_dict[doc_id_1]\n",
    "        num_pairs_confirmed = 0\n",
    "    else:\n",
    "        doc_id_2_list = []\n",
    "        num_pairs_confirmed = \"\"\n",
    "\n",
    "    # evaluate each supposed pair\n",
    "    \n",
    "    num_expected_pairs = len(doc_id_2_list)\n",
    "    for doc_id_2 in doc_id_2_list:\n",
    "        \n",
    "        something_to_say = True\n",
    "\n",
    "        # format four ranked scores as \"rank (score)\"\n",
    "        topic_all_scores = format_score_summary(all_topic_candidates, doc_id_2)\n",
    "        topic_priority_scores = format_score_summary(priority_topic_candidates, doc_id_2)\n",
    "        tf_idf_scores = format_score_summary(tf_idf_candidates, doc_id_2)\n",
    "        sw_w_scores = format_score_summary(sw_w_candidates, doc_id_2)\n",
    "\n",
    "        # format results for output to spreadsheet\n",
    "        output_buffer_1 += '\\t'.join([\n",
    "            str(i),\n",
    "            doc_id_1,\n",
    "            doc_id_2,\n",
    "            topic_all_scores,\n",
    "            topic_priority_scores,\n",
    "            tf_idf_scores,\n",
    "            sw_w_scores,\n",
    "        ]) + '\\n'\n",
    "        \n",
    "        # have msg ready to confirm in notebook significant scores for suspected pairs\n",
    "        if sw_w_scores == \"\":\n",
    "            rank = 0\n",
    "            sw_w_abs_score = 0\n",
    "        else:\n",
    "            rank_str, sw_w_abs_score_str = sw_w_scores.split(' ', 1)\n",
    "            rank = int(rank_str)\n",
    "            sw_w_abs_score = float(sw_w_abs_score_str[1:-1])\n",
    "        \n",
    "        confirmation_msg = (0 < rank <= rank_threshold) * '(CONFIRMED)'\n",
    "        num_pairs_confirmed += bool(confirmation_msg) * 1\n",
    "\n",
    "        # output to notebook\n",
    "        i += 1\n",
    "        print(\"pair #{}/{} ({}, {}): {} {} {} {} {}\".format(\n",
    "            i, num_expected_pairs,\n",
    "            doc_id_1, doc_id_2,\n",
    "            topic_all_scores,\n",
    "            topic_priority_scores,\n",
    "            tf_idf_scores,\n",
    "            sw_w_scores,\n",
    "            confirmation_msg\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # also report novel findings\n",
    "        \n",
    "    num_novel_pairs = {30: 0, 40: 0, 50: 0}\n",
    "    for k,v in sw_w_candidates.items():\n",
    "\n",
    "        if v > sw_w_min_threshold and k not in doc_id_2_list:\n",
    "            \n",
    "            something_to_say = True\n",
    "\n",
    "            for threshold in num_novel_pairs.keys():\n",
    "                if v > threshold:\n",
    "                    num_novel_pairs[threshold] += 1\n",
    "\n",
    "            # format four ranked scores as \"rank (score)\"\n",
    "            topic_all_scores = format_score_summary(all_topic_candidates, k)\n",
    "            topic_priority_scores = format_score_summary(priority_topic_candidates, k)\n",
    "            tf_idf_scores = format_score_summary(tf_idf_candidates, k)\n",
    "            sw_w_scores = format_score_summary(sw_w_candidates, k)\n",
    "\n",
    "            # format results for output to spreadsheet\n",
    "            output_buffer_1 += '\\t'.join([\n",
    "                \"no id\",\n",
    "                doc_id_1,\n",
    "                k,\n",
    "                topic_all_scores,\n",
    "                topic_priority_scores,\n",
    "                tf_idf_scores,\n",
    "                sw_w_scores,\n",
    "            ]) + '\\n'\n",
    "\n",
    "            # output to notebook\n",
    "            print(\"NOVEL PAIR ({}, {}): {} {} {} {}\".format(\n",
    "                doc_id_1, k,\n",
    "                topic_all_scores,\n",
    "                topic_priority_scores,\n",
    "                tf_idf_scores,\n",
    "                sw_w_scores,\n",
    "                )\n",
    "            )\n",
    "        \n",
    "        # stop once scores too low\n",
    "        elif (v < sw_w_min_threshold):\n",
    "            break\n",
    "    \n",
    "    if num_expected_pairs > 0:\n",
    "        print(\"expected pairs confirmed (@{}): {}/{}\".format(rank_threshold, num_pairs_confirmed, num_expected_pairs))\n",
    "    if num_novel_pairs[sw_w_threshold_for_display] > 0:\n",
    "        print(\"novel pairs (@{}): {}\".format(sw_w_min_threshold, num_novel_pairs[sw_w_threshold_for_display]))\n",
    "        \n",
    "    # give explicit negative output in notebook if there are neither suspected pairs nor novel findings\n",
    "    if not something_to_say:\n",
    "        print(\"(none)\")\n",
    "\n",
    "    # prepare final summary of doc_1 output to second file\n",
    "    output_buffer_2 += \"{}\\t{}\\t{}\\t{}\\t{}\\t{}\".format(\n",
    "        doc_id_1, num_expected_pairs, num_pairs_confirmed,\n",
    "        num_novel_pairs[50], num_novel_pairs[40], num_novel_pairs[30]\n",
    "        ) + '\\n'\n",
    "        \n",
    "    # update progress bar as last thing\n",
    "    pbar.update()        \n",
    "\n",
    "            \n",
    "# finish up\n",
    "\n",
    "with open('pairs.tsv','w') as f_out_1:\n",
    "    f_out_1.write(output_buffer_1)\n",
    "\n",
    "with open('doc_1_summaries.tsv','w') as f_out_2:\n",
    "    f_out_2.write(output_buffer_2)\n",
    "    \n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
